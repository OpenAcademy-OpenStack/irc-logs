02:04:51 <subbu_allamaraju> #startmeeting weekly-syncup
02:04:51 <gluong> re-ran ./stack.sh and that seemed to start up keystone
02:04:52 <osoabot> Meeting started Wed Jan 29 02:04:51 2014 UTC.  The chair is subbu_allamaraju. Information about MeetBot at http://wiki.debian.org/MeetBot.
02:04:53 <osoabot> Useful Commands: #action #agreed #help #info #idea #link #topic.
02:05:27 <subbu_allamaraju> The agenda today is to review https://github.com/OpenAcademy-OpenStack/project-docs/blob/master/projects.md
02:05:52 <subbu_allamaraju> We have dading, thuc and myself from eBay
02:06:13 <subbu_allamaraju> I've setup a google doc to note project preferences - https://docs.google.com/a/subbu.org/spreadsheet/ccc?key=0ApntcBgpHeZldHhaaTI1V2NBb0JqbUZSWkZJS3dFV1E&usp=drive_web#gid=0
02:06:25 <subbu_allamaraju> This is to record first and second preferences
02:06:35 <Srinivasan> sorry, wifi issues.
02:06:39 <subbu_allamaraju> np
02:06:53 <subbu_allamaraju> Before we get started, any other topics on the agenda?
02:07:07 <subbu_allamaraju> Any feedback from devstack experience so far?
02:07:09 <vishwa> hi subbu, I don't think we have write preferences on the google doc
02:07:34 <subbu_allamaraju> vishwa: fixed
02:08:08 <subbu_allamaraju> If no other items on the agenda we can get started
02:08:57 <gluong> I was wondering if there will be any starter/good-first-bugs to work on
02:09:02 <gluong> prior to the project start
02:09:27 <subbu_allamaraju> Would another group exercise help?
02:09:36 <theocean154> yep
02:09:54 <theocean154> also as people get questions, email all the google group
02:09:59 <subbu_allamaraju> I think thuc has one ready.
02:10:23 <vishwa> yea I agree, another exercise would be great to get more familiarized
02:10:30 <thuc> I added one https://github.com/OpenAcademy-OpenStack/project-docs/blob/master/exercises/instance_connectivity_check.md
02:10:33 <gluong> I think it would be good to dive further into the codebase and push some code if the time permits
02:11:43 <subbu_allamaraju> How about this - once we discuss the projects, and we have a general consensus on who would like to work on what, we can tweak the exercise to be in that area. OpenStack is very large.
02:12:21 <Yu> I agree
02:12:33 <gluong> sounds good
02:12:42 <subbu_allamaraju> Great
02:12:53 <subbu_allamaraju> Let's go project by project
02:13:11 <subbu_allamaraju> First is to introduce two factor auth.
02:14:10 <subbu_allamaraju> As you saw in the first exercise, users have to include their crendentials in scripts/code to talk to OpenStack APIs.
02:15:08 <subbu_allamaraju> This may be okay in some cases, but there is a chance of leaking. Recently someone put his AWS credentials in a script and accidentally leaked it. Someone else abused the credentials. He noticed that and revoked the credentials since those were temporary.
02:15:13 <subbu_allamaraju> In OpenStack there is no equivalent.
02:15:35 <subbu_allamaraju> There are also situations where policies dictate that credentials should not be stored like that.
02:15:49 <subbu_allamaraju> That's the general idea.
02:16:49 <deen> hello everybody
02:16:54 <subbu_allamaraju> Hi deen
02:17:05 <deen> Hey Subbu.
02:17:13 <subbu_allamaraju> We are just discussing the projects. Started with the first one on https://github.com/OpenAcademy-OpenStack/project-docs/blob/master/projects.md
02:17:51 <Srinivasan> as for the actual code generation part
02:17:52 <deen> There are some people on the channel #OpenAcademy-OpenStack
02:17:57 <subbu_allamaraju> The work in this area involves changes to keystone, horizon (UI), UI etc
02:18:10 <subbu_allamaraju> Srinivasan: I included a python example
02:18:44 <subbu_allamaraju> For example, http://throwingfire.com/you-can-be-a-twofactor-hero/ shows how to mint a token, show a qr code to the user in a browser, and register with the Google Authenticator app
02:19:08 <Srinivasan> okay, got t.
02:19:10 <deen> Ok.
02:19:14 <subbu_allamaraju> As part of the design process we will have to decide what goes into the token
02:20:14 <subbu_allamaraju> There was a blueprint in OpenStack. We will resurrect it, and try to submit code to OpenStack.
02:20:45 <subbu_allamaraju> So it is important to polish the code and maintain the same conventions, unit tests etc.
02:20:55 <subbu_allamaraju> any other questions on this project?
02:21:40 <atheendra> Is there any reason for choosing this method over others?
02:21:48 <subbu_allamaraju> such as?
02:22:23 <atheendra> Like a key within the user space which does not require the use of a username/password at all?
02:23:08 <subbu_allamaraju> Sure. We can discuss alternatives.
02:23:42 <atheendra> OK, sounds good.
02:23:43 <subbu_allamaraju> I also encourage you try how two factor auth works on google, AWS etc
02:24:03 <subbu_allamaraju> The next one is Access Keys.
02:24:41 <subbu_allamaraju> This is in the same problem domain.
02:25:10 <subbu_allamaraju> BTW - just noticed In the above I mixed up the credential store use case in the first project.
02:25:27 <subbu_allamaraju> Please ignore that. Access keys is there to avoid storing shared credentails
02:25:31 <vishwa> yes subbu I was confused :)
02:25:39 <subbu_allamaraju> me too :)
02:25:49 <subbu_allamaraju> Sorry about that
02:25:57 <subbu_allamaraju> long day
02:26:10 <subbu_allamaraju> thoughts on this?
02:26:41 <vishwa> would this be similar to the way AWS handles access keys and secret keys?
02:27:04 <subbu_allamaraju> exactly
02:27:13 <subbu_allamaraju> but in OpenStack style
02:27:46 <vishwa> great!
02:28:15 <Srinivasan> how would this be temperery?
02:28:17 <subbu_allamaraju> Both projects will take atleast two.
02:28:44 <subbu_allamaraju> They won't be temporary, but the user can set an expiration time when askign for them
02:28:44 <Srinivasan> or is it up to the user to revoke the keys like on aws
02:28:51 <Srinivasan> ah okay
02:28:51 <subbu_allamaraju> exactly
02:29:27 <subbu_allamaraju> The next one is Flyway
02:29:41 <subbu_allamaraju> this is fairly complex as it involves multiple APIs.
02:30:10 <subbu_allamaraju> This is not an uncommon problem in private cloud situations.
02:30:45 <subbu_allamaraju> For instance, about a year ago we had an OpenStack deployment running Essex version of OpenStack, and we could not do a clean live upgrade to Folsom.
02:31:09 <subbu_allamaraju> So we ended up writing a tool like this to forklift VMs from one deployment to another.
02:31:20 <subbu_allamaraju> Downtime for each VM was about 5 minutes
02:31:39 <subbu_allamaraju> This was a fun exercise.
02:32:37 <subbu_allamaraju> This project involves good understanding of APIs like Keystone and Glance, as well as how nova-compute manages VMs.
02:32:54 <vishwa> in what way will this project be different from the tool that you'd developed Subbu?
02:33:09 <subbu_allamaraju> because we wrote a throw-away project
02:33:22 <subbu_allamaraju> It was not good enough for reuse.
02:33:31 <vishwa> ah I see, this would be a far more refined solution then
02:33:44 <subbu_allamaraju> We refine it to be reusable on any OpenStack cloud
02:34:02 <subbu_allamaraju> I'm sure a lot of operators will silently thanking the team that builds this.
02:34:10 <subbu_allamaraju> will be
02:34:55 <dading> subbu_allamaraju the vm needs a little clarification, like what aspects of the vm should be copied.
02:35:11 <subbu_allamaraju> Let me share how we did this
02:36:04 <subbu_allamaraju> KVM manages the VM on the local disk on nova-compute node. You can see this in nova/virt/libvirt package
02:36:24 <subbu_allamaraju> We created a VM of the same flavor on the destination first.
02:37:01 <subbu_allamaraju> Then shutdown the VM on the source, and copy the file from the old compute node to the new one
02:37:11 <subbu_allamaraju> nova would not know that the file changed on the disk
02:37:23 <subbu_allamaraju> I mean nova on the dest cloud
02:37:54 <subbu_allamaraju> one of the challenge is to orchestrate this change so that we can move hundreds of VMs in parallel
02:38:19 <subbu_allamaraju> in one run, we migrated over 1000 VMs in about two hours
02:38:31 <subbu_allamaraju> so, we need to solve for performance as well.
02:38:48 <subbu_allamaraju> we will need to select some framework to do this concurrently
02:39:01 <subbu_allamaraju> We used celery at that time, but there may  be better options now.
02:39:28 <subbu_allamaraju> thuc - would you like todescribe Repoman?
02:39:50 <thuc> sure
02:40:35 <thuc> The purpose is to reclaim unused VMs.
02:41:04 <thuc> These could be VMs that are inaccessible due to failures during boot time.
02:41:22 <thuc> VMs whose owners are no longer active
02:41:53 <thuc> And also VMs that are no longer needed.
02:43:35 <thuc> The last one is tricky as it involves notifying the users
02:44:03 <subbu_allamaraju> BTW this problem is relevant in private clouds more than public, since public clouds would gladly bill users
02:44:30 <gluong> would there be an UI component to this?
02:44:41 <gluong> or how will the service interact with the operator
02:45:05 <thuc> UI would be one way to do it.
02:45:50 <subbu_allamaraju> I guess once there is an API, UI and CLI can come in
02:46:06 <gluong> sounds good thank you
02:46:39 <thuc> questions?
02:48:02 <subbu_allamaraju> can we move to the next one then?
02:48:08 <gluong> yes
02:48:21 <subbu_allamaraju> dading - would you like to describe?
02:48:32 <dading> yep
02:49:02 <dading> right now the scheduler in nova is implemented in such a simple way
02:49:27 <dading> that it gets update from hypervisors every couple of mins
02:49:49 <dading> and base on that it goes through all the hypervisors when it needs to schedule a new instance
02:50:11 <dading> since there can be multiple filter applied
02:51:17 <dading> so basically the time cost for scheduling is linear of the number of filter * number of hypervisors
02:51:47 <dading> another problem is,
02:52:26 <dading> right now the scheduler doing static filter validation, and it does not take consideration of the runtime work load
02:52:59 <dading> so for example if there is a peak of provision,
02:53:33 <dading> it's likely to schedule all requests to small amount of hypervisors
02:53:48 <dading> leads to poor performance in that case.
02:54:08 <dading> this project is to address the performance of scheduling logic
02:54:25 <jevonyeoh> for the runtime, are there other models to possibly refer to for inspiration?
02:54:26 <subbu_allamaraju> sorry to interrupt - just doing a timecheck. Are folks okay to stay for a few more minutes to complete this
02:54:38 <gluong> np here
02:54:39 <atheendra> Sure.
02:54:42 <vishwa> Sure
02:54:53 <Yu> Suew
02:54:58 <Yu> Sure*
02:55:01 <subbu_allamaraju> thx
02:55:15 <dading> jevonyeoh: this is what to be identified in this project.
02:55:25 <dading> there can be multiple factors
02:55:45 <dading> that can be used to balance the selection of hypervisor
02:55:58 <dading> and as an output of this project
02:56:18 <jevonyeoh> ah ok, sounds interesting
02:56:33 <dading> we need to evaluate different factors, develop a framework to simulate different traffic,
02:56:51 <dading> and validate the performance based on the data
02:57:20 <dading> question?
02:57:32 <vishwa> dading: the case that you mention when you say "leads to poor performance in that case", how often does that occur in your opinion?
02:58:46 <dading> vishwa: this will depend on user behavior, but in many PaaS use case, users will provision a bunch of vms at same time
02:59:13 <subbu_allamaraju> Any other questions?
02:59:51 <subbu_allamaraju> Moving to the next one
02:59:56 <vishwa> dading: Why do you say that the scheduler will schedule all the requests to a small amount of hypervisors in peak of provision?
03:00:05 <vishwa> oh sorry subbu!
03:00:09 <subbu_allamaraju> I'll wait
03:00:39 <dading> vishwa: one reason is scheduler doesn't take consideration of other requests at that time.
03:00:58 <dading> it is basically static logic not based on runtime situation
03:01:12 <subbu_allamaraju> welcome ropeck
03:01:28 <vishwa> thanks for clearing that up dading!
03:01:30 <subbu_allamaraju> We're discussing project 5 on https://github.com/OpenAcademy-OpenStack/project-docs/blob/master/projects.md
03:02:02 <ropeck> hi there!  finally got my irc going correctly
03:03:37 <subbu_allamaraju> moving to the next one
03:04:12 <subbu_allamaraju> This project came up recently as we often run into performance issues that are extremely difficult to simulate in a lab setup
03:04:49 <subbu_allamaraju> Some of these problems show up when we have a large number of hypervisors
03:05:02 <subbu_allamaraju> Here is an example.
03:05:23 <subbu_allamaraju> nova-compute nodes emit a heartbeat about VMs to nova.
03:05:30 <subbu_allamaraju> These messages go over rabbitmq.
03:05:57 <subbu_allamaraju> Sometimes rabbitmq gets clogged up and usually melts down a good chunk of OpenStack APIs
03:06:07 <subbu_allamaraju> We deal with such issues in real life
03:06:30 <subbu_allamaraju> So the idea is whether we can simulate such conditions without needing so much hardware
03:06:49 <subbu_allamaraju> we're talking about 400+ nodes
03:07:44 <subbu_allamaraju> With a simulator, we can inject a fake driver that makes it look like there are VMs. Basically nova-compute fakes it out when it gets a request to create a VM.
03:08:00 <subbu_allamaraju> This allows us to simulate load with a small setup.
03:08:26 <subbu_allamaraju> The takeaway for you is that you will learn how to write a driver for nova-compute and go through the full lifecycle
03:08:57 <subbu_allamaraju> It allows any OpenStack operator to simulate their control plane (i.e. APIs, schedulers, rabbitmq, database etc)
03:08:59 <subbu_allamaraju> for load
03:09:33 <subbu_allamaraju> We will go through the flows of these projects again when we meet in about 10 days from now
03:09:51 <subbu_allamaraju> comments? questions?
03:10:37 <Yu> So what are we supposed to do during the 10 days?
03:11:00 <subbu_allamaraju> tough question ;)
03:11:24 <gluong> I believe there is still the hibernation of VM instances project that hasn't been mentioned
03:11:38 <subbu_allamaraju> correct
03:12:13 <subbu_allamaraju> Yu - We have another short exercise to finish. Once that is done, we will finalize selection, and start working. Why wait?
03:12:35 <gluong> when should we expect the final selection to be announced?
03:12:46 <subbu_allamaraju> As I indicated earlier, there are going to five of us to mentor.
03:12:47 <Yu> OK. Got it : )
03:13:13 <subbu_allamaraju> gluong: shooting for this week. However, it is not clear how many students we have. Let's resume this after the last project
03:13:30 <subbu_allamaraju> ropeck: your way
03:14:06 <ropeck> I added the vm hibernation project today - I can give a quick description, or answer questions if there are any
03:15:04 <ropeck> I missed the beginning of the chat, so I don't know what the discussion style is, so I'll try to be brief.
03:15:43 <subbu_allamaraju> please go ahead to give an overview
03:15:43 <ropeck> The project's use case is when a hypervisor is full and we know many of the vms are not really needed today but could be difficult to recreate.
03:16:26 <ropeck> The intent is to make it simpler to remove them and recreate them with our tool than to try to justify using hypervisor resources every few weeks.
03:16:56 <ropeck> As I wrote in the email earlier, this is sort of a hard suspend of the vm.
03:17:59 <ropeck> If we only use 'nova pause' or 'nova suspend', the vm will still be present on the hypervisor taking local disk space and other resources.  The hibernated instance is not on the hypervisor.  It's only a disk and metadata file on a swift cluster.